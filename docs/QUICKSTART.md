# ðŸš€ Quick Start Guide - SmartGrocy

**Last Updated:** November 12, 2025
**Status:** Demo-Ready with Interactive Dashboard & Modern Pipeline
**Default Data:** POC (1% sample) with 100% PRODUCT_ID matching
**Dashboard:** Available at reports/dashboard/index.html

---

## âš¡ TL;DR (30-Second Setup)

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Khá»Ÿi táº¡o data quality monitoring
python scripts/setup_data_quality.py

# 3. Cháº¡y pipeline hiá»‡n Ä‘áº¡i vá»›i monitoring
python run_modern_pipeline.py

# 4. GiÃ¡m sÃ¡t cháº¥t lÆ°á»£ng dá»¯ liá»‡u
python scripts/monitor_data_quality.py

# 5. Táº¡o dashboard tÆ°Æ¡ng tÃ¡c
python scripts/create_dashboard.py

# Má»Ÿ dashboard: reports/dashboard/index.html
```

---

## ðŸ“¦ SmartGrocy Features

### Modern Pipeline vá»›i Data Quality Monitoring

| Component | SmartGrocy âœ… |
|-----------|----------------|
| **Pipeline Orchestration** | Prefect-based DAG workflow |
| **Data Quality Monitoring** | Great Expectations + custom validations |
| **Alerting System** | Tá»± Ä‘á»™ng cáº£nh bÃ¡o cháº¥t lÆ°á»£ng dá»¯ liá»‡u vÃ  lá»—i pipeline |
| **Intelligent Caching** | Tá»‘i Æ°u hÃ³a hiá»‡u nÄƒng vá»›i disk-based caching |
| **Performance Monitoring** | Theo dÃµi bottleneck vÃ  tá»‘i hÃ³a tÃ i nguyÃªn |
| **Drift Detection** | PhÃ¡t hiá»‡n thay Ä‘á»•i phÃ¢n phá»‘i dá»¯ liá»‡u theo thá»i gian |
| **Data Granularity** | Aggregated weekly `[PRODUCT_ID, STORE_ID, WEEK_NO]` |
| **Missing Periods** | Zero-filled complete grid |
| **Train/Test Split** | Time-based (weeks 1-83 vs 84-104) - leak-safe |
| **Lag Features** | 100% leak-safe (on lagged series) |
| **Model Type** | 7 quantile models (Q05/Q10/Q25/Q50/Q75/Q90/Q95) |
| **Evaluation Metric** | Pinball loss + Prediction Interval Coverage |
| **Tests** | 6 smoke tests + validation script + comprehensive testing |
| **Dev Tooling** | ruff, black, isort, mypy |
| **Dashboard** | Interactive HTML with Plotly charts |
| **License** | MIT License |

**Bottom Line:** SmartGrocy lÃ  **há»‡ thá»‘ng dá»± bÃ¡o hiá»‡n Ä‘áº¡i vá»›i monitoring cháº¥t lÆ°á»£ng dá»¯ liá»‡u, leak-safe, probabilistic, vÃ  production-ready**.

---

## ðŸ“‹ Prerequisites

- **Python**: 3.10, 3.11, or 3.12
- **RAM**: 4GB+ recommended (8GB+ for full dataset)
- **Disk Space**: 2GB+ for data and models

---

## ðŸŽ¯ Step-by-Step Walkthrough

### Step 1: Install Dependencies (2 minutes)

```bash
# Core dependencies (pandas, lightgbm, prefect, great_expectations, etc.)
pip install -r requirements.txt
```

**Key Dependencies:**
- **Prefect**: Pipeline orchestration vÃ  workflow management
- **Great Expectations**: Data quality monitoring vÃ  validation
- **LightGBM/XGBoost**: Machine learning models
- **Polars/Pandas**: High-performance data processing
- **Plotly**: Interactive dashboards

### Step 2: Setup Data Quality Monitoring (1 minute)

Khá»Ÿi táº¡o há»‡ thá»‘ng monitoring cháº¥t lÆ°á»£ng dá»¯ liá»‡u:

```bash
python scripts/setup_data_quality.py
```

**What happens:**
- Táº¡o Great Expectations configuration
- Setup data validation rules
- Khá»Ÿi táº¡o alerting system
- Táº¡o data quality checkpoints

### Step 4: Validate Setup (10 seconds)

Run the validation script to ensure everything is configured correctly:

```bash
python scripts/validate_setup.py
```

**Expected Output:**
```
======================================================================
DATASTORM PIPELINE VALIDATION
======================================================================

[1/5] Testing module imports...
  âœ“ All modules import successfully

[2/5] Testing directory structure...
  âœ“ data\poc_data
  âœ“ data\processed
  âœ“ models
  âœ“ reports\metrics
  âœ“ tests

[3/5] Testing POC data...
  âœ“ POC transaction data exists: 26,229 rows

[4/5] Testing configuration files...
  âœ“ pyproject.toml
  âœ“ requirements-dev.txt

[5/5] Testing WS0 aggregation (functional test)...
  âœ“ Aggregation successful: 1,000 rows â†’ 957 rows

VALIDATION COMPLETE
```

### Step 4: Run Smoke Tests (30 seconds)

Run the automated test suite to verify core functionality:

```bash
pytest tests/test_smoke.py -v -m smoke
```

**Expected Output:**
```
tests/test_smoke.py::test_data_loader PASSED
tests/test_smoke.py::test_ws0_aggregation PASSED
tests/test_smoke.py::test_ws2_timeseries_features PASSED
tests/test_smoke.py::test_time_based_split PASSED
tests/test_smoke.py::test_quantile_model_config PASSED
tests/test_smoke.py::test_directory_structure PASSED

============== 6 passed in 28.43s ==============
```

### Step 5: Run Modern Pipeline vá»›i Monitoring (2-5 minutes)

Cháº¡y pipeline hiá»‡n Ä‘áº¡i vá»›i data quality monitoring:

```bash
python run_modern_pipeline.py --full-data
```

**What Happens:**
1. **Data Quality Check:** Validate data quality vá»›i Great Expectations
2. **Pipeline Orchestration:** Prefect manages workflow execution
3. **Data Loading:** Reads tá»« `data/2_raw/` hoáº·c `data/1_poc_data/`
4. **WS0 (Aggregation):** Aggregates transactions to weekly level, creates master grid
5. **WS1 (Relational):** Joins product vÃ  household demographics
6. **WS2 (Time-Series):** Creates leak-safe lag/rolling features
7. **WS4 (Price/Promo):** Adds promotion indicators vÃ  price features
8. **WS5-WS6:** Additional features (stockout recovery, weather)
9. **Quality Validation:** Continuous data quality checks
10. **Training:** Trains 7 quantile models (Q05/Q10/Q25/Q50/Q75/Q90/Q95)
11. **Saves:** Models + metrics + quality reports

**Expected Runtime:**
- POC data (1%): ~2 minutes
- Full data (100%): ~45 minutes vá»›i monitoring

---

## ðŸ”¬ Understanding the Pipeline Stages

### WS0: Aggregation & Master Grid (NEW!)

**What it does:**
```
Raw transactions (multiple rows per product-store-week)
    â†“
Aggregate to [PRODUCT_ID, STORE_ID, WEEK_NO]
    â†“
Create complete grid (all combinations)
    â†“
Zero-fill missing periods
    â†“
Sort by time (CRITICAL for leak-safe features)
```

**Why it matters:**
- **Consistent granularity:** One row per product-store-week
- **No gaps:** Missing weeks filled with 0 sales (correct for sparse retail data)
- **Leak-safe foundation:** Sorted by time enables proper lag calculations

**File:** `src/features/ws0_aggregation.py`

### WS1: Relational Features

**What it does:**
- Joins product metadata (department, commodity)
- Joins household demographics (if available)

**File:** `src/features/ws1_relational_features.py`

### WS2: Time-Series Features (LEAK-SAFE!)

**What it does:**
```python
# Lags (never include current row)
sales_value_lag_1    # t-1 week
sales_value_lag_4    # t-4 weeks (1 month)
sales_value_lag_8    # t-8 weeks (2 months)
sales_value_lag_12   # t-12 weeks (3 months)

# Rolling stats (calculated on lagged series)
rolling_mean_4_lag_1   # Mean of [t-1, t-2, t-3, t-4]
rolling_std_4_lag_1    # Std dev of same window
rolling_mean_8_lag_1   # Mean of [t-1 through t-8]
rolling_std_8_lag_1

# Calendar features
week_of_year  # 1-52
month_proxy   # 1-12
quarter       # 1-4
week_sin/cos  # Cyclical encoding
```

**Why it's leak-safe:**
- Lags start from `t-1` (never `t-0`)
- Rolling windows on `lag_1` column (window = `[t-1, t-2, ..., t-N]`)
- First week of each product-store has NaN for lag_1 (cannot compute)

**File:** `src/features/ws2_timeseries_features.py`

### WS4: Price & Promotion Features

**What it does:**
- Calculates base price, discounts, discount percentages
- Merges causal data (display, mailer, retail promos)
- Creates binary flags: `is_on_display`, `is_on_mailer`, etc.

**File:** `src/features/ws4_price_features.py`

### WS5: Stockout Recovery Features

**What it does:**
- Detects vÃ  handles stockout patterns
- Creates recovery indicators sau stockouts
- Models demand recovery behavior

**File:** `src/features/ws5_stockout_recovery.py`

### WS6: Weather Features (Optional)

**What it does:**
- Integrates weather data náº¿u available
- Creates weather impact features
- Seasonal weather patterns

**File:** `src/features/ws6_weather_features.py`

### Model Training: Enhanced Quantile Regression

**What it does:**
1. **Time-based split:** Train on weeks 1-83, test on weeks 84-104
2. **Train 7 models:**
   - Q05/Q10/Q25: Lower bounds (5th/10th/25th percentiles)
   - Q50: Median forecast (best estimate)
   - Q75/Q90/Q95: Upper bounds (75th/90th/95th percentiles)
3. **Evaluate:** Pinball loss + Prediction Interval Coverage
4. **Ensemble:** Weighted combination cá»§a multiple quantiles
5. **Save:** 7 model files + feature config + metrics

**Why 7 quantile models?**
- **Granular probabilistic forecasting:** Chi tiáº¿t hÆ¡n vá» uncertainty
- **Better inventory optimization:** Multiple safety stock levels
- **Enhanced dynamic pricing:** Flexible discounting strategies
- **Ensemble methods:** Combine predictions for better accuracy

**Files:** `src/pipelines/_03_model_training.py`, `src/pipelines/_06_ensemble.py`

---

## ðŸ“Š Interpreting the Results

After running the pipeline, check these files:

### 1. Feature Table: `data/processed/master_feature_table.parquet`

```python
import pandas as pd

df = pd.read_parquet('data/processed/master_feature_table.parquet')
print(df.shape)  # e.g., (1,234,567, 35) rows Ã— columns
print(df.columns.tolist())  # All features from WS0-WS4
print(df.head())
```

**Key columns:**
- `PRODUCT_ID`, `STORE_ID`, `WEEK_NO` (grouping keys)
- `SALES_VALUE`, `QUANTITY` (aggregated targets)
- `sales_value_lag_1/4/8/12` (time-series lags)
- `rolling_mean/std_4/8/12_lag_1` (rolling features)
- `is_on_display`, `is_on_mailer` (promotion flags)
- `week_of_year`, `month_proxy` (calendar)

### 2. Trained Models: `models/q{05,10,25,50,75,90,95}_forecaster.joblib`

```python
import joblib

# Load 7 quantile models
models = {}
for q in [0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95]:
    models[q] = joblib.load(f'models/q{int(q*100):02d}_forecaster.joblib')

print(models[0.50])  # LGBMRegressor(objective='quantile', alpha=0.5, ...)
```

### 3. Metrics: `reports/metrics/quantile_model_metrics.json`

```json
{
  "q05_pinball_loss": 12.34,
  "q10_pinball_loss": 15.67,
  "q25_pinball_loss": 18.21,
  "q50_pinball_loss": 20.45,
  "q75_pinball_loss": 22.12,
  "q90_pinball_loss": 24.89,
  "q95_pinball_loss": 26.34,
  "prediction_interval_coverage_90": 0.897,
  "prediction_interval_coverage_80": 0.856,
  "ensemble_pinball_loss": 19.23
}
```

**How to interpret:**
- **Pinball loss:** Lower is better (measures quantile accuracy)
- **Coverage:** Should be ~80-90% for intervals
  - 90% interval (Q05-Q95): target ~90%
  - 80% interval (Q10-Q90): target ~80%
- **Ensemble:** Combined prediction quality

---

## ðŸ§ª Testing & Development

### Run Individual Smoke Tests

```bash
# Test data loading
pytest tests/test_smoke.py::test_data_loader -v

# Test aggregation
pytest tests/test_smoke.py::test_ws0_aggregation -v

# Test time-series features
pytest tests/test_smoke.py::test_ws2_timeseries_features -v

# Test time-based split
pytest tests/test_smoke.py::test_time_based_split -v
```

### Run Linting

```bash
# Manual code formatting and linting
ruff check src/ tests/ --fix
black src/ tests/
isort src/ tests/
mypy src/
```

### Debug a Single Stage

```bash
# Run modern pipeline vá»›i monitoring
python run_modern_pipeline.py

# Hoáº·c run tá»«ng stage riÃªng láº»:
# Data loading
python -c "from src.pipelines._01_load_data import load_data; dataframes, config = load_data(); print('Data loaded')"

# Feature enrichment
python -c "from src.pipelines._02_feature_enrichment import main; main()"

# Model training
python -c "from src.pipelines._03_model_training import main; main()"

# Ensemble predictions
python -c "from src.pipelines._06_ensemble import main; main()"
```

---

## ðŸŽ“ Common Questions

### Q: How do I use the trained models for forecasting?

```python
import joblib
import pandas as pd

# Load models
model_q05 = joblib.load('models/q05_forecaster.joblib')
model_q50 = joblib.load('models/q50_forecaster.joblib')
model_q95 = joblib.load('models/q95_forecaster.joblib')

# Load new data (must have same features as training data)
X_new = pd.read_parquet('data/processed/master_feature_table.parquet')
X_future = X_new[X_new['WEEK_NO'] > 104]  # Weeks beyond training data

# Make predictions
forecast_q05 = model_q05.predict(X_future)  # Lower bound
forecast_q50 = model_q50.predict(X_future)  # Best estimate
forecast_q95 = model_q95.predict(X_future)  # Upper bound

# Calculate safety stock for inventory optimization
safety_stock = forecast_q95 - forecast_q50
```

### Q: How do I run on the full dataset (not POC)?

Modern pipeline tá»± Ä‘á»™ng detect vÃ  sá»­ dá»¥ng full dataset:

```bash
# Cháº¡y trÃªn full dataset tá»« data/2_raw/
python run_modern_pipeline.py --full-data

# Hoáº·c chá»‰ Ä‘á»‹nh rÃµ:
export DATA_SOURCE=full
python run_modern_pipeline.py --full-data
```

**Note:** Full dataset requires 16GB+ RAM vÃ  ~45 minutes runtime vá»›i monitoring.

### Q: What if I get import errors?

Make sure you're running from the project root:
```bash
cd c:\Users\Admin\.vscode\datastorm
python src/pipelines/_04_run_pipeline.py
```

If still failing, add project to PYTHONPATH:
```bash
export PYTHONPATH="${PYTHONPATH}:$(pwd)"  # Linux/Mac
set PYTHONPATH=%PYTHONPATH%;%CD%          # Windows
```

### Q: How do I know if there's data leakage?

Run the smoke test:
```bash
pytest tests/test_smoke.py::test_time_based_split -v
pytest tests/test_smoke.py::test_ws2_timeseries_features -v
```

Both tests explicitly check for leakage:
- Time split: `assert train['WEEK_NO'].max() < test['WEEK_NO'].min()`
- Lag features: `assert first_weeks['sales_value_lag_1'].isna().all()`

---

## ðŸ“š Further Reading

- **QA Fix Log:** `reports/QA_FIXLOG.md` - Detailed root cause analysis of all issues fixed
- **Refactoring Summary:** `reports/REFACTORING_SUMMARY.md` - Executive summary
- **Original README:** `README.md` - Business context and project overview

---

## ðŸ†˜ Troubleshooting

| Problem | Solution |
|---------|----------|
| `FileNotFoundError: transaction_data.csv` | Run `python scripts/create_sample_data.py` first |
| `Import errors` | Ensure you're in project root: `cd c:\Users\Admin\.vscode\datastorm` |
| `Pytest not found` | Install dev dependencies: `pip install -r requirements-dev.txt` |
| `Models not saved` | Check `models/` directory exists (created by validation script) |
| `Slow pipeline` | Use POC data (1%) for testing: `data/poc_data/` instead of `data/raw/` |
| `Pre-commit failing` | Run manually: `ruff check --fix; black .` |

---

## âœ… Success Checklist

Before considering SmartGrocy "working", verify:

- [ ] âœ… Data quality setup: `python scripts/setup_data_quality.py`
- [ ] âœ… Validation script passes: `python scripts/validate_setup.py`
- [ ] âœ… All smoke tests pass: `pytest tests/test_smoke.py -v -m smoke`
- [ ] âœ… Modern pipeline runs: `python run_modern_pipeline.py --full-data`
- [ ] âœ… 7 model files saved: `models/q{05,10,25,50,75,90,95}_forecaster.joblib`
- [ ] âœ… Metrics file created: `reports/metrics/quantile_model_metrics.json`
- [ ] âœ… Ensemble predictions: `reports/ensemble_predictions.csv`
- [ ] âœ… Dashboard created: `reports/dashboard/index.html`
- [ ] âœ… Data quality reports: Check alerting logs

---

## ðŸ“š Documentation

For detailed information about SmartGrocy:

- **[OPERATIONS.md](./OPERATIONS.md)**: HÆ°á»›ng dáº«n deployment vÃ  váº­n hÃ nh production
- **[CONTRIBUTING.md](./CONTRIBUTING.md)**: HÆ°á»›ng dáº«n Ä‘Ã³ng gÃ³p cho dá»± Ã¡n
- **[CHANGELOG.md](./CHANGELOG.md)**: Lá»‹ch sá»­ thay Ä‘á»•i vÃ  updates
- **[TEST_README.md](./TEST_README.md)**: TÃ i liá»‡u vá» testing vÃ  validation

---

**Happy Forecasting! ðŸš€**
