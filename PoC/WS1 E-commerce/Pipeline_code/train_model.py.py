import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score
import warnings
import time
import sys
import joblib  # Má»šI: DÃ¹ng Ä‘á»ƒ lÆ°u mÃ´ hÃ¬nh
import json  # Má»šI: DÃ¹ng Ä‘á»ƒ lÆ°u metrics vÃ  features

warnings.filterwarnings('ignore')

# -----------------------------------------------------------------
# 1. Cáº¤U HÃŒNH Dá»° ÃN
# -----------------------------------------------------------------
CONFIG = {
    # File Ä‘áº§u vÃ o (tá»« pipeline)
    "data_file": "olist_master_table_final.csv",

    # Files Ä‘áº§u ra (Artifacts)
    "model_output_path": "lgbm_review_model_v1.joblib",
    "features_output_path": "model_features_v1.json",
    "metrics_output_path": "model_metrics_v1.json",

    # Cáº¥u hÃ¬nh Tuning (Báº¡n cÃ³ thá»ƒ tÄƒng/giáº£m n_iter Ä‘á»ƒ cháº¡y nhanh/cháº­m)
    "tuning_iterations": 25,  # Thá»­ 25 tá»• há»£p
    "cv_folds": 3  # Cross-validation 3 láº§n
}


# -----------------------------------------------------------------
# 2. CÃC HÃ€M CHá»¨C NÄ‚NG
# -----------------------------------------------------------------

def load_data(filepath):
    """Táº£i dá»¯ liá»‡u sáº¡ch tá»« pipeline."""
    print(f"[HÃ m load_data] Äang táº£i dá»¯ liá»‡u tá»«: {filepath}...")
    start_time = time.time()
    try:
        if filepath.endswith('.parquet'):
            df = pd.read_parquet(filepath)
        else:
            df = pd.read_csv(filepath)
        print(f"âœ“ Táº£i xong. Shape: {df.shape}. (Máº¥t {time.time() - start_time:.2f}s)")
        return df
    except FileNotFoundError:
        print(f"ğŸš¨ Lá»–I: KhÃ´ng tÃ¬m tháº¥y file {filepath}.")
        sys.exit(1)
    except Exception as e:
        print(f"ğŸš¨ Lá»–I khi táº£i file: {e}")
        sys.exit(1)


def prepare_data(df):
    """Lá»c, táº¡o biáº¿n má»¥c tiÃªu, chá»n Ä‘áº·c trÆ°ng, vÃ  chia dá»¯ liá»‡u."""
    print("[HÃ m prepare_data] Äang chuáº©n bá»‹ dá»¯ liá»‡u...")

    # Lá»c dá»¯ liá»‡u (chá»‰ huáº¥n luyá»‡n trÃªn Ä‘Æ¡n Ä‘Ã£ giao & cÃ³ review)
    if 'order_status' in df.columns:
        df_model = df[(df['order_status'] == 'delivered') & (df['review_score'] > 0)].copy()
    else:
        df_model = df[(df['delivery_time_days'] > -999) & (df['review_score'] > 0)].copy()

    if df_model.empty:
        print("ğŸš¨ Lá»–I: KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u Ä‘Ã£ giao vÃ  Ä‘Ã£ review Ä‘á»ƒ huáº¥n luyá»‡n.")
        sys.exit(1)

    # Táº¡o biáº¿n má»¥c tiÃªu (Y)
    target_col = 'is_good_review'
    df_model[target_col] = (df_model['review_score'] == 5).astype(int)
    print(f"PhÃ¢n bá»• biáº¿n má»¥c tiÃªu (Y):")
    print(df_model[target_col].value_counts(normalize=True).apply(lambda x: f"{x:.1%}"))

    # Äá»‹nh nghÄ©a vÃ  kiá»ƒm tra Ä‘áº·c trÆ°ng
    numeric_features = [
        'delivery_time_days', 'delivery_vs_estimated_days', 'order_processing_time_days',
        'price', 'freight_value', 'freight_ratio', 'payment_value_total',
        'payment_installments_total', 'payment_sequential_count', 'dist_cust_seller_km',
        'product_weight_g', 'product_volume_cm3', 'purchase_day_of_week', 'purchase_hour'
    ]
    categorical_features = [
        'product_category_name_english', 'customer_state', 'seller_state',
        'payment_type_primary', 'is_weekend'
    ]

    all_features = [col for col in (numeric_features + categorical_features) if col in df.columns]
    categorical_features = [col for col in categorical_features if col in all_features]

    if not all_features:
        print("ğŸš¨ Lá»–I: KhÃ´ng tÃ¬m tháº¥y báº¥t ká»³ Ä‘áº·c trÆ°ng nÃ o trong file.")
        sys.exit(1)

    X = df_model[all_features]
    y = df_model[target_col]

    # Chuyá»ƒn Ä‘á»•i dtype cho LightGBM
    print(f"Äang chuyá»ƒn Ä‘á»•i {len(categorical_features)} cá»™t sang 'category' dtype...")
    for col in categorical_features:
        X[col] = X[col].astype('category')

    # Chia Train/Test
    print("Äang chia Train/Test (80/20)...")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=0.2,
        random_state=42,
        stratify=y
    )
    print("âœ“ Chuáº©n bá»‹ dá»¯ liá»‡u hoÃ n táº¥t.")

    # Tráº£ vá» cáº£ danh sÃ¡ch Ä‘áº·c trÆ°ng Ä‘á»ƒ lÆ°u láº¡i
    return X_train, X_test, y_train, y_test, all_features, categorical_features


def tune_model(X_train, y_train, categorical_features):
    """Tinh chá»‰nh hyperparameters báº±ng RandomizedSearchCV."""
    print("[HÃ m tune_model] Báº¯t Ä‘áº§u tinh chá»‰nh siÃªu tham sá»‘...")
    start_train = time.time()

    # TÃ­nh trá»ng sá»‘ (scale_pos_weight)
    try:
        scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()
        print(f"Máº¥t cÃ¢n báº±ng: Tá»· lá»‡ (Xáº¥u/Tá»‘t) lÃ  {scale_pos_weight:.2f}")
    except ZeroDivisionError:
        scale_pos_weight = 1

        # KhÃ´ng gian tham sá»‘
    param_grid = {
        'n_estimators': [200, 500, 1000, 1500],
        'learning_rate': [0.01, 0.02, 0.05, 0.1],
        'num_leaves': [20, 31, 40, 50],
        'max_depth': [-1, 10, 15, 20],
        'colsample_bytree': [0.7, 0.8, 0.9, 1.0],
        'subsample': [0.7, 0.8, 0.9, 1.0],
        'reg_alpha': [0, 0.1, 0.5],
        'reg_lambda': [0, 0.1, 0.5]
    }

    kfold = StratifiedKFold(n_splits=CONFIG['cv_folds'], shuffle=True, random_state=42)

    base_model = lgb.LGBMClassifier(
        random_state=42,
        scale_pos_weight=scale_pos_weight,
        n_jobs=-1
    )

    # Khá»Ÿi táº¡o trÃ¬nh tÃ¬m kiáº¿m
    random_search = RandomizedSearchCV(
        estimator=base_model,
        param_distributions=param_grid,
        n_iter=CONFIG['tuning_iterations'],
        cv=kfold,
        scoring='roc_auc',  # DÃ¹ng ROC AUC Ä‘á»ƒ tá»‘i Æ°u cho P/L máº¥t cÃ¢n báº±ng
        n_jobs=-1,
        random_state=42,
        verbose=1
    )

    # Huáº¥n luyá»‡n
    random_search.fit(
        X_train,
        y_train,
        categorical_feature=categorical_features
    )

    print(f"\nâœ“ Tinh chá»‰nh hoÃ n táº¥t (Máº¥t {time.time() - start_train:.2f}s)")
    print("\n" + "=" * 50)
    print("           MÃ” HÃŒNH Tá»I Æ¯U NHáº¤T ÄÃƒ TÃŒM THáº¤Y")
    print("=" * 50)
    print(f"Äiá»ƒm (ROC AUC) tá»‘t nháº¥t: {random_search.best_score_:.4f}")
    print("CÃ¡c tham sá»‘ tá»‘t nháº¥t:")
    print(random_search.best_params_)
    print("=" * 50)

    # Tráº£ vá» mÃ´ hÃ¬nh tá»‘t nháº¥t
    return random_search.best_estimator_


def evaluate_model(model, X_test, y_test):
    """ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh cuá»‘i cÃ¹ng trÃªn táº­p Test vÃ  tráº£ vá» dict metrics."""
    print("[HÃ m evaluate_model] Äang Ä‘Ã¡nh giÃ¡ trÃªn táº­p Test...")
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]

    # TÃ­nh toÃ¡n metrics
    accuracy = accuracy_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    report_dict = classification_report(y_test, y_pred, target_names=['Bad (0)', 'Good (1)'], output_dict=True)
    report_str = classification_report(y_test, y_pred, target_names=['Bad (0)', 'Good (1)'])
    cm = confusion_matrix(y_test, y_pred)

    # In ra console
    print("\n" + "=" * 50)
    print("      Káº¾T QUáº¢ ÄÃNH GIÃ MÃ” HÃŒNH (TRÃŠN Táº¬P TEST)")
    print("=" * 50)
    print(f"ğŸ¯ Accuracy (Äá»™ chÃ­nh xÃ¡c): {accuracy:.2%}")
    print(f"ğŸ¯ ROC AUC: {roc_auc:.4f}")
    print("\nğŸ“Š BÃ¡o cÃ¡o PhÃ¢n loáº¡i:")
    print(report_str)
    print("\nğŸ”¢ Ma tráº­n nháº§m láº«n:")
    print(pd.DataFrame(cm, index=['Actual: Bad', 'Actual: Good'], columns=['Predicted: Bad', 'Predicted: Good']))
    print("=" * 50)

    # ÄÃ³ng gÃ³i metrics Ä‘á»ƒ lÆ°u file
    metrics = {
        "accuracy": accuracy,
        "roc_auc": roc_auc,
        "classification_report": report_dict,
        "confusion_matrix": cm.tolist()  # Chuyá»ƒn sang list Ä‘á»ƒ lÆ°u JSON
    }
    return metrics


def save_artifacts(model, features_config, metrics):
    """LÆ°u mÃ´ hÃ¬nh, danh sÃ¡ch Ä‘áº·c trÆ°ng, vÃ  metrics ra file."""
    print("[HÃ m save_artifacts] Äang lÆ°u cÃ¡c 'artifacts' cá»§a mÃ´ hÃ¬nh...")

    # 1. LÆ°u mÃ´ hÃ¬nh
    try:
        joblib.dump(model, CONFIG['model_output_path'])
        print(f"âœ“ MÃ´ hÃ¬nh Ä‘Ã£ lÆ°u táº¡i: {CONFIG['model_output_path']}")
    except Exception as e:
        print(f"ğŸš¨ Lá»–I khi lÆ°u mÃ´ hÃ¬nh: {e}")

    # 2. LÆ°u cáº¥u hÃ¬nh Ä‘áº·c trÆ°ng
    try:
        with open(CONFIG['features_output_path'], 'w') as f:
            json.dump(features_config, f, indent=4)
        print(f"âœ“ Cáº¥u hÃ¬nh Ä‘áº·c trÆ°ng Ä‘Ã£ lÆ°u táº¡i: {CONFIG['features_output_path']}")
    except Exception as e:
        print(f"ğŸš¨ Lá»–I khi lÆ°u file features: {e}")

    # 3. LÆ°u metrics
    try:
        with open(CONFIG['metrics_output_path'], 'w') as f:
            json.dump(metrics, f, indent=4)
        print(f"âœ“ Metrics Ä‘Ã£ lÆ°u táº¡i: {CONFIG['metrics_output_path']}")
    except Exception as e:
        print(f"ğŸš¨ Lá»–I khi lÆ°u file metrics: {e}")


# -----------------------------------------------------------------
# 3. HÃ€M CHÃNH (MAIN ORCHESTRATOR)
# -----------------------------------------------------------------

def main():
    """Äiá»u phá»‘i toÃ n bá»™ quy trÃ¬nh huáº¥n luyá»‡n."""
    print("========== Báº®T Äáº¦U QUY TRÃŒNH HUáº¤N LUYá»†N MÃ” HÃŒNH ==========")
    total_start_time = time.time()

    # BÆ¯á»šC 1: Táº£i dá»¯ liá»‡u
    print("\n--- BÆ¯á»šC 1: Táº¢I Dá»® LIá»†U ---")
    df = load_data(CONFIG['data_file'])

    # BÆ¯á»šC 2: Chuáº©n bá»‹ dá»¯ liá»‡u
    print("\n--- BÆ¯á»šC 2: CHUáº¨N Bá»Š Dá»® LIá»†U & CHIA Táº¬P ---")
    X_train, X_test, y_train, y_test, features, cat_features = prepare_data(df)

    # BÆ¯á»šC 3: Tinh chá»‰nh (Tune) mÃ´ hÃ¬nh
    print("\n--- BÆ¯á»šC 3: TINH CHá»ˆNH MÃ” HÃŒNH (TUNING) ---")
    best_model = tune_model(X_train, y_train, cat_features)

    # BÆ¯á»šC 4: ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh tá»‘t nháº¥t
    print("\n--- BÆ¯á»šC 4: ÄÃNH GIÃ MÃ” HÃŒNH CUá»I CÃ™NG ---")
    metrics = evaluate_model(best_model, X_test, y_test)

    # BÆ¯á»šC 5: LÆ°u "Artifacts"
    print("\n--- BÆ¯á»šC 5: LÆ¯U ARTIFACTS (MÃ” HÃŒNH, FEATURES, METRICS) ---")
    features_config = {
        "all_features": features,
        "categorical_features": cat_features
    }
    save_artifacts(best_model, features_config, metrics)

    print("\n========================================================")
    print(f"ğŸ¥³ HOÃ€N THÃ€NH! Tá»•ng thá»i gian cháº¡y: {time.time() - total_start_time:.2f} giÃ¢y.")
    print(f"CÃ¡c file káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {CONFIG['model_output_path']} vÃ  cÃ¡c file .json liÃªn quan.")
    print("========================================================")


# --- ÄIá»‚M Báº®T Äáº¦U CHáº Y SCRIPT ---
if __name__ == "__main__":
    main()